{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping Suburbs to SA2 Areas\n",
    "#### Jeremy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Obtained from\n",
    "https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.001July%202016?OpenDocument  \n",
    "https://discover.data.vic.gov.au/dataset/rental-report-quarterly-moving-annual-rents-by-suburb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading SA2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefiles\n",
    "suburbs = gpd.read_file('../data/mappings/SAL_2021_AUST_GDA2020_SHP/SAL_2021_AUST_GDA2020.shp')\n",
    "sa2_areas = gpd.read_file('../data/mappings/SA2_2021_AUST_SHP_GDA2020/SA2_2021_AUST_GDA2020.shp')\n",
    "\n",
    "print(suburbs.columns)\n",
    "print(sa2_areas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample text data from the suburbs GeoDataFrame\n",
    "print(\"Suburbs Data Sample:\")\n",
    "print(suburbs[['SAL_NAME21', 'STE_NAME21', 'AUS_NAME21']].head())\n",
    "\n",
    "# Display sample text data from the SA2 areas GeoDataFrame\n",
    "print(\"\\nSA2 Areas Data Sample:\")\n",
    "print(sa2_areas[['SA2_NAME21', 'SA3_NAME21', 'SA4_NAME21', 'GCC_NAME21', 'STE_NAME21']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to include only Victoria\n",
    "suburbs_victoria = suburbs[suburbs['STE_NAME21'] == 'Victoria']\n",
    "sa2_victoria = sa2_areas[sa2_areas['STE_NAME21'] == 'Victoria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the suburbs\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = suburbs_victoria.plot(edgecolor='k', alpha=0.5)\n",
    "ax.set_title('Suburbs of Australia')\n",
    "plt.show()\n",
    "\n",
    "# Plot the SA2 areas\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = sa2_victoria.plot(edgecolor='k', alpha=0.5)\n",
    "ax.set_title('SA2 Areas of Australia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Moving Annual Rent by Suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all sheets into a dictionary of DataFrames\n",
    "dfs_rent = pd.read_excel('../data/landing/Moving annual rent by suburb - March quarter 2024.xlsx', sheet_name=None)\n",
    "\n",
    "# Access a specific sheet by its name\n",
    "df_rent = dfs_rent['All properties'].drop(columns=['Moving annual rent by suburb'])\n",
    "df_flat1 = dfs_rent['1 bedroom flat'].drop(columns=['Moving annual rent by suburb'])\n",
    "df_flat2 = dfs_rent['2 bedroom flat'].drop(columns=['Moving annual rent by suburb'])\n",
    "df_flat3 = dfs_rent['3 bedroom flat'].drop(columns=['Moving annual rent by suburb'])\n",
    "df_house2 = dfs_rent['2 bedroom house'].drop(columns=['Moving annual rent by suburb'])\n",
    "df_house3 = dfs_rent['3 bedroom house'].drop(columns=['Moving annual rent by suburb'])\n",
    "df_house4 = dfs_rent['4 bedroom house'].drop(columns=['Moving annual rent by suburb'])\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df_rent['Unnamed: 1'].head(10))\n",
    "print(df_rent.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date range from March 2000 to March 2024, but only for quarters (March, June, September, December)\n",
    "quarterly_range = pd.date_range(start='2000-03-01', end='2024-03-01', freq='QS-MAR')\n",
    "\n",
    "# Generate the column names using the quarterly range, alternating between 'COUNT' and 'MEDIAN'\n",
    "new_column_names = ['Suburbs']  # First column remains 'Suburbs'\n",
    "for date in quarterly_range:\n",
    "    quarter_year = date.strftime('%B%Y').upper()  # Format: 'MARCH2000', 'JUNE2000', etc.\n",
    "    new_column_names.append(f'{quarter_year}COUNT')\n",
    "    new_column_names.append(f'{quarter_year}MEDIAN')\n",
    "\n",
    "# Map the old column names ('Unnamed: 1', 'Unnamed: 2', ...) to the new ones\n",
    "old_column_names = ['Unnamed: ' + str(i) for i in range(1, len(new_column_names)+ 1)]\n",
    "\n",
    "# Apply the renaming\n",
    "# Apply the renaming for all DataFrames\n",
    "df_rent = df_rent.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "df_flat1 = df_flat1.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "df_flat2 = df_flat2.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "df_flat3 = df_flat3.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "df_house2 = df_house2.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "df_house3 = df_house3.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "df_house4 = df_house4.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
    "\n",
    "# Rename specific column in all DataFrames\n",
    "df_rent.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "df_flat1.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "df_flat2.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "df_flat3.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "df_house2.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "df_house3.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "df_house4.rename(columns={'Lease commenced in year ending ': 'MARCH2000COUNT'}, inplace=True)\n",
    "\n",
    "# Drop the specified rows from all DataFrames\n",
    "df_rent = df_rent.drop([0, 1])\n",
    "df_flat1 = df_flat1.drop([0, 1])\n",
    "df_flat2 = df_flat2.drop([0, 1])\n",
    "df_flat3 = df_flat3.drop([0, 1])\n",
    "df_house2 = df_house2.drop([0, 1])\n",
    "df_house3 = df_house3.drop([0, 1])\n",
    "df_house4 = df_house4.drop([0, 1])\n",
    "\n",
    "# Print out the new column names to verify\n",
    "print(df_rent.columns)\n",
    "print(df_rent.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rent.to_csv('../data/raw/annual_moving_rent/all_properties.csv', index=False)\n",
    "df_flat1.to_csv('../data/raw/annual_moving_rent/1_bedroom_flat.csv', index=False)\n",
    "df_flat2.to_csv('../data/raw/annual_moving_rent/2_bedroom_flat.csv', index=False)\n",
    "df_flat3.to_csv('../data/raw/annual_moving_rent/3_bedroom_flat.csv', index=False)\n",
    "df_house2.to_csv('../data/raw/annual_moving_rent/2_bedroom_house.csv', index=False)\n",
    "df_house3.to_csv('../data/raw/annual_moving_rent/3_bedroom_house.csv', index=False)\n",
    "df_house4.to_csv('../data/raw/annual_moving_rent/4_bedroom_house.csv', index=False)\n",
    "\n",
    "sa2_victoria.to_file(\"../data/raw/SA2_VIC/sa2_areas_vic.shp\", driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping to SA2 Areas using Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load datasets\n",
    "df_rent = pd.read_csv('../data/raw/annual_moving_rent/all_properties.csv')\n",
    "df_flat1 = pd.read_csv('../data/raw/annual_moving_rent/1_bedroom_flat.csv')\n",
    "df_flat2 = pd.read_csv('../data/raw/annual_moving_rent/2_bedroom_flat.csv')\n",
    "df_flat3 = pd.read_csv('../data/raw/annual_moving_rent/3_bedroom_flat.csv')\n",
    "df_house2 = pd.read_csv('../data/raw/annual_moving_rent/2_bedroom_house.csv')\n",
    "df_house3 = pd.read_csv('../data/raw/annual_moving_rent/3_bedroom_house.csv')\n",
    "df_house4 = pd.read_csv('../data/raw/annual_moving_rent/4_bedroom_house.csv')\n",
    "\n",
    "# Step 2: Keep only relevant columns for each DataFrame\n",
    "relevant_columns = ['Suburbs', 'MARCH2024MEDIAN', 'MARCH2024COUNT']\n",
    "\n",
    "df_rent = df_rent[relevant_columns]\n",
    "df_flat1 = df_flat1[relevant_columns]\n",
    "df_flat2 = df_flat2[relevant_columns]\n",
    "df_flat3 = df_flat3[relevant_columns]\n",
    "df_house2 = df_house2[relevant_columns]\n",
    "df_house3 = df_house3[relevant_columns]\n",
    "df_house4 = df_house4[relevant_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flat1.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_FLAT1',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_FLAT1'\n",
    "}, inplace=True)\n",
    "\n",
    "df_flat2.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_FLAT2',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_FLAT2'\n",
    "}, inplace=True)\n",
    "\n",
    "df_flat3.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_FLAT3',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_FLAT3'\n",
    "}, inplace=True)\n",
    "\n",
    "df_house2.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_HOUSE2',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_HOUSE2'\n",
    "}, inplace=True)\n",
    "\n",
    "df_house3.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_HOUSE3',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_HOUSE3'\n",
    "}, inplace=True)\n",
    "\n",
    "df_house4.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_HOUSE4',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_HOUSE4'\n",
    "}, inplace=True)\n",
    "\n",
    "# For the rent DataFrame (assuming it's meant to have no specific type suffix)\n",
    "df_rent.rename(columns={\n",
    "    'MARCH2024MEDIAN': 'MARCH2024MEDIAN_RENT',\n",
    "    'MARCH2024COUNT': 'MARCH2024COUNT_RENT'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_to_merge = [df_flat1, df_flat2, df_flat3, df_house2, df_house3, df_house4]\n",
    "\n",
    "# Use reduce to merge all DataFrames iteratively\n",
    "from functools import reduce\n",
    "\n",
    "# Start with the rent DataFrame\n",
    "combined_df = df_rent\n",
    "\n",
    "# Define a function for merging while handling potential duplicates\n",
    "def merge_dfs(left, right):\n",
    "    return pd.merge(left, right, on='Suburbs', how='outer')\n",
    "\n",
    "# Merge all DataFrames using reduce\n",
    "combined_df = reduce(merge_dfs, dataframes_to_merge, combined_df)\n",
    "\n",
    "# Remove duplicates if necessary\n",
    "combined_df.drop_duplicates(subset='Suburbs', inplace=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df.head())\n",
    "print(f\"Total Rows: {len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "gdf_sa2 = gpd.read_file(\"../data/mappings/GDA94/vic_localities.shp\")\n",
    "\n",
    "# Extract the list of SA2 names\n",
    "sa2_names = gdf_sa2['LOC_NAME'].tolist()\n",
    "\n",
    "# Function to find the closest match\n",
    "def get_best_match(suburb_name, choices):\n",
    "    if pd.isna(suburb_name):\n",
    "        return None\n",
    "    match, score = process.extractOne(suburb_name, choices)\n",
    "    return match\n",
    "\n",
    "# Convert 'Suburbs' column to string and apply fuzzy matching\n",
    "combined_df['Suburbs'] = combined_df['Suburbs'].astype(str)\n",
    "combined_df['Suburb_name'] = combined_df['Suburbs'].apply(lambda x: get_best_match(x, sa2_names))\n",
    "\n",
    "# Merge with the SA2 shapefile\n",
    "# Use 'Best_Match_SA2' to merge on the SA2 shapefile's SA2_NAME21\n",
    "merged_combined_df = pd.merge(gdf_sa2, combined_df, left_on='LOC_NAME', right_on='Suburb_name', how='left')\n",
    "\n",
    "# Drop the 'Best_Match_SA2' column if no longer needed\n",
    "merged_combined_df.drop(columns=['Suburb_name'], inplace=True)\n",
    "\n",
    "# Remove rows where suburbs did not match (NaN after merge)\n",
    "merged_combined_df.dropna(subset=['Suburbs'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory and file name for the merged dataset\n",
    "output_dir = \"../data/curated/sa2_rent/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Name the output CSV file\n",
    "csv_output_path = os.path.join(output_dir, \"merged_final.csv\")\n",
    "\n",
    "# Save the merged DataFrame to a CSV\n",
    "merged_combined_df.to_csv(csv_output_path, index=False)\n",
    "print(f\"Saved merged DataFrame to {csv_output_path}\")\n",
    "\n",
    "# Output number of rows and sample of the merged DataFrame\n",
    "print(f\"Number of rows in merged combined DataFrame: {len(merged_combined_df)}\")\n",
    "print(merged_combined_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
